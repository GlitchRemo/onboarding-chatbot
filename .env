# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# Server Configuration
PORT=3000

# Model Configuration
EMBEDDING_MODEL=nomic-embed-text
LLM_MODEL=llama2

# Vector Store Configuration
VECTOR_STORE_TYPE=memory
CHUNK_SIZE=1000
CHUNK_OVERLAP=200